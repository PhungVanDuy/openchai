base_model: NousResearch/Llama-2-7b-hf
base_model_config: NousResearch/Llama-2-7b-hf

datasets:
  - path: ChaiML/davinci_1k_samples
    type: chatml
  - path: ChaiML/soda_10k_samples
    type: input_output

dataset_prepared_path: last_run_prepared
val_set_size: 0.01
output_dir: llama2-out

sequence_len: 1024

wandb_project: openchai
wandb_entity: pvduy

gradient_accumulation_steps: 2
micro_batch_size: 4
num_epochs: 3
learning_rate: 0.00002

bf16: true

gradient_checkpointing: true
logging_steps: 1
flash_attention: true

eval_steps: 200
